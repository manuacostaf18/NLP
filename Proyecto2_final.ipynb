{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017037f5-05b7-4e53-b46e-55c49de92d22",
   "metadata": {
    "id": "017037f5-05b7-4e53-b46e-55c49de92d22"
   },
   "source": [
    "# Proyecto 2: De clasificación a NER\n",
    "\n",
    "Andrés Felipe Gámez, Camilo Andrés Gómez y Manuela Acosta Fajardo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902946ae-afe0-4e47-8ff9-edfade62239d",
   "metadata": {
    "id": "902946ae-afe0-4e47-8ff9-edfade62239d"
   },
   "source": [
    "En este proyecto utilizarán [este dataset](https://archive.ics.uci.edu/ml/datasets/Paper+Reviews) que consiste en evaluaciones de diferentes revisores sobre papers (405). Cada evaluación ha sido etiquetada con 5 clases (muy negativo, negativo, 0, neutral, positivo y muy positivo). Este proyecto consiste en realizar una clasificación de este dataset y además identificar que parte de los comentarios hacen referencia a las clases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc45e3c-0145-4ac5-a14d-a9d0dd8c49e6",
   "metadata": {
    "id": "3dc45e3c-0145-4ac5-a14d-a9d0dd8c49e6"
   },
   "source": [
    "## Parte 1. Clasificación sencilla de cada revisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268c2a4-5889-4ebf-a752-ddb9f24fa9a4",
   "metadata": {
    "id": "2268c2a4-5889-4ebf-a752-ddb9f24fa9a4"
   },
   "source": [
    "En esta parte tendrá que hacer un modelo de clasificación usando redes recurrentes (LSTM, GRU), para los cinco tipos de categorias.  Recuerde algunos pasos para realizar la clasificación:\n",
    "\n",
    "1. Lectura de los datos (división en training/validation sets)\n",
    "2. Preprocesamiento del texto (no es necesario ser tanto preprocesamiento como en word2vec, pero si eliminar algunos carácteres o incluso revisar si hay comentarios vacíos). \n",
    "3. Creación del vocabulario y transformación de palabras a índices (y viceversa)\n",
    "4. Creación del \"dataset\" y \"dataloader\" involucrando los pasos 2 y 3.\n",
    "5. Creación del modelo, involucrando embeddings.\n",
    "6. Entrenar y validar (escoger optimizador Adam o AdamW, función de costo apropiada, loops de entrenamiento y validación).\n",
    "7. Modelo listo para producción (modelo para predecir entrando un comentario)\n",
    "8. Pequeña interfaz para predicción usando Gradio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3097b89-f3d3-48a1-b904-f8301f475245",
   "metadata": {
    "id": "e3097b89-f3d3-48a1-b904-f8301f475245"
   },
   "source": [
    "Realice diferentes configuraciones, tamaño del embedding, arquitecturas LSTM o GRU, varias capas, bidireccionalidad, etc. Escoja el mejor modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084bfb2-c0ab-4dad-9c12-a432cbc5b09f",
   "metadata": {
    "id": "c084bfb2-c0ab-4dad-9c12-a432cbc5b09f"
   },
   "source": [
    "-----\n",
    "Es importante que realicen gráficos y visualizaciones que ayuden a la interpretación. No olviden ir analizando y comentando los hallazgos, y sobretodo **concluir**. El entregable es un notebook de Jupyter, debidamente presentado y comentado.\n",
    "\n",
    "- ¿Qué diferencian encuentran con un tipo de clasificación respecto al otro?\n",
    "- ¿Los pesos de una tarea ayudan a la otra?\n",
    "- ¿Es posible analizar o intuir a partir de pesos o activaciones, que parte del texto está ayudando en la parte 1 a clasificar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "B27pfpI8dIhp",
   "metadata": {
    "id": "B27pfpI8dIhp"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import gradio as gr\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import vocab\n",
    "from unicodedata import normalize\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4rSeo72fadmg",
   "metadata": {
    "id": "4rSeo72fadmg"
   },
   "source": [
    "Cargamos los datos del archivo para obtener el dataframe y eliminamos aquellas revisiones que no tienen comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c259170-4bb7-4a78-aa90-9d4a74032ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-16T12:39:42.781316Z",
     "iopub.status.busy": "2022-03-16T12:39:42.781113Z",
     "iopub.status.idle": "2022-03-16T12:39:42.789084Z",
     "shell.execute_reply": "2022-03-16T12:39:42.788609Z",
     "shell.execute_reply.started": "2022-03-16T12:39:42.781295Z"
    },
    "id": "5c259170-4bb7-4a78-aa90-9d4a74032ca4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data using Python JSON module\n",
    "with open('reviews.json','r') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "df = pd.json_normalize(data['paper'], record_path = [\"review\"])\n",
    "\n",
    "#quitando comentarios vacios\n",
    "DF=df['text'][df['text']=='']\n",
    "data=df.drop(DF.index.tolist(),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cIXdvxyOazRv",
   "metadata": {
    "id": "cIXdvxyOazRv"
   },
   "source": [
    "Definimos las funciones de preprocesamiento del texto, para quitar tildes,pasar a minúsculas, eliminar algunos caracteres especiales como números y guiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "zn1nMWeLdBsx",
   "metadata": {
    "id": "zn1nMWeLdBsx"
   },
   "outputs": [],
   "source": [
    "def quitartildes(s):\n",
    "    s = re.sub(\n",
    "            r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "            normalize( \"NFD\", s), 0, re.I\n",
    "        )\n",
    "    \n",
    "    return normalize( 'NFC', s)\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "\n",
    "  l=(re.sub(r'[(0-9)]','',quitartildes(sentence)).lower().split())\n",
    "  k=[i for i in l if i!='-']\n",
    "  return ' '.join(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0xTU_m3CdWYu",
   "metadata": {
    "id": "0xTU_m3CdWYu"
   },
   "outputs": [],
   "source": [
    "data['text_clean']=data['text'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dhkM70BjmPvA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "dhkM70BjmPvA",
    "outputId": "3f0e6bd9-b310-4aa1-eade-24e55f6c6ba4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3eb1b2cb-776b-4f40-8e94-31f6445be027\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>id</th>\n",
       "      <th>lan</th>\n",
       "      <th>orientation</th>\n",
       "      <th>remarks</th>\n",
       "      <th>text</th>\n",
       "      <th>timespan</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>- El artículo aborda un problema contingente y...</td>\n",
       "      <td>2010-07-05</td>\n",
       "      <td>el articulo aborda un problema contingente y m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>El artículo presenta recomendaciones prácticas...</td>\n",
       "      <td>2010-07-05</td>\n",
       "      <td>el articulo presenta recomendaciones practicas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>- El tema es muy interesante y puede ser de mu...</td>\n",
       "      <td>2010-07-05</td>\n",
       "      <td>el tema es muy interesante y puede ser de much...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Se explica en forma ordenada y didáctica una e...</td>\n",
       "      <td>2010-07-05</td>\n",
       "      <td>se explica en forma ordenada y didactica una e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Los autores describen una metodología para des...</td>\n",
       "      <td>2010-07-05</td>\n",
       "      <td>los autores describen una metodologia para des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "      <td>-2</td>\n",
       "      <td></td>\n",
       "      <td>El trabajo pretende ofrecer una visión del uso...</td>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>el trabajo pretende ofrecer una vision del uso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>es</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>El paper está bien escrito y de fácil lectura....</td>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>el paper esta bien escrito y de facil lectura....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Observación de fondo:  No se presenta un ejemp...</td>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>observacion de fondo: no se presenta un ejempl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>es</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>Se propone un procedimiento para elaborar máqu...</td>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>se propone un procedimiento para elaborar maqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>El artículo describe básicamente los component...</td>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>el articulo describe basicamente los component...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3eb1b2cb-776b-4f40-8e94-31f6445be027')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3eb1b2cb-776b-4f40-8e94-31f6445be027 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3eb1b2cb-776b-4f40-8e94-31f6445be027');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    confidence evaluation  id lan orientation remarks  \\\n",
       "0            4          1   1  es           0           \n",
       "1            4          1   2  es           1           \n",
       "2            5          1   3  es           1           \n",
       "3            4          2   1  es           1           \n",
       "5            4          2   3  es           0           \n",
       "..         ...        ...  ..  ..         ...     ...   \n",
       "400          5         -1   1  es          -2           \n",
       "401          4         -1   2  es          -1           \n",
       "402          4         -1   1  es           0           \n",
       "403          3          1   2  es          -1           \n",
       "404          4          1   1  es          -1           \n",
       "\n",
       "                                                  text    timespan  \\\n",
       "0    - El artículo aborda un problema contingente y...  2010-07-05   \n",
       "1    El artículo presenta recomendaciones prácticas...  2010-07-05   \n",
       "2    - El tema es muy interesante y puede ser de mu...  2010-07-05   \n",
       "3    Se explica en forma ordenada y didáctica una e...  2010-07-05   \n",
       "5    Los autores describen una metodología para des...  2010-07-05   \n",
       "..                                                 ...         ...   \n",
       "400  El trabajo pretende ofrecer una visión del uso...  2015-07-05   \n",
       "401  El paper está bien escrito y de fácil lectura....  2015-07-05   \n",
       "402  Observación de fondo:  No se presenta un ejemp...  2015-07-05   \n",
       "403  Se propone un procedimiento para elaborar máqu...  2015-07-05   \n",
       "404  El artículo describe básicamente los component...  2015-07-05   \n",
       "\n",
       "                                            text_clean  \n",
       "0    el articulo aborda un problema contingente y m...  \n",
       "1    el articulo presenta recomendaciones practicas...  \n",
       "2    el tema es muy interesante y puede ser de much...  \n",
       "3    se explica en forma ordenada y didactica una e...  \n",
       "5    los autores describen una metodologia para des...  \n",
       "..                                                 ...  \n",
       "400  el trabajo pretende ofrecer una vision del uso...  \n",
       "401  el paper esta bien escrito y de facil lectura....  \n",
       "402  observacion de fondo: no se presenta un ejempl...  \n",
       "403  se propone un procedimiento para elaborar maqu...  \n",
       "404  el articulo describe basicamente los component...  \n",
       "\n",
       "[399 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8Bj9Qg0kbJEX",
   "metadata": {
    "id": "8Bj9Qg0kbJEX"
   },
   "source": [
    "Tomamos de los notebooks del curso, la clase `TextData` para facilitar el manejo de los datos y la división en training y validación. Por lo que, dividimos los datos en 70% entrenamiento y 30% validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "NM4iOxybmxp_",
   "metadata": {
    "id": "NM4iOxybmxp_"
   },
   "outputs": [],
   "source": [
    "class TextData(Dataset):\n",
    "    '''\n",
    "    Dataset basico para leer los datos de tweets\n",
    "    '''\n",
    "    def __init__(self, dataFrame):\n",
    "        super(TextData, self).__init__()\n",
    "        #df = pd.read_csv(filename,encoding='latin-1')\n",
    "        self.df = dataFrame[[\"evaluation\", \"text_clean\"]]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.df.iloc[index,0], self.df.iloc[index,1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "PW2mQAROmyo4",
   "metadata": {
    "id": "PW2mQAROmyo4"
   },
   "outputs": [],
   "source": [
    "TextD= TextData(data)\n",
    "train_dataset, valid_dataset = random_split(TextD,[int(len(TextD)*0.7),len(TextD) - int(len(TextD)*0.7)], torch.manual_seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vW7lnd4GceD2",
   "metadata": {
    "id": "vW7lnd4GceD2"
   },
   "source": [
    "Ahora, procesando los datos de entrenamiento creamos el vocabulario e introducimos los tokens para palabras desconocidas y de relleno en caso de que se necesitan a la hora de procesar la información para ingresarla a la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ferHSgUPnVDn",
   "metadata": {
    "id": "ferHSgUPnVDn"
   },
   "outputs": [],
   "source": [
    "tok_c = Counter()\n",
    "for label, line in train_dataset:\n",
    "    tokens = line.split()\n",
    "    tok_c.update(tokens)\n",
    "\n",
    "\n",
    "sorted_by_freq_tuples = sorted(tok_c.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "vocab = vocab(ordered_dict)\n",
    "\n",
    "vocab.insert_token(\"<pad>\", 0)\n",
    "vocab.insert_token(\"<unk>\", 1)\n",
    "vocab.set_default_index(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GJ4vN9-OczII",
   "metadata": {
    "id": "GJ4vN9-OczII"
   },
   "source": [
    "Definimos la función `collate_batch` que procesa el texto para ponerlo en el formato que puede recibir la red. Para ellos usamos dos funciones auxiliares: `text_pipeline` que pasa de palabras a índices y `label_pipeline` que reordena los labels del dataset para que coincidan con las posiciones del arreglo de salida de la red, por ejemplo, la clase *muy negativo* tiene label **-2** pero la función `label_pipeline` la reasigna al label 0 para hacer más fácil el calculo del accuracy y del loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Z2Avms23n-fb",
   "metadata": {
    "id": "Z2Avms23n-fb"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "text_pipeline = lambda x: [vocab[token] for token in x.split()]\n",
    "label_pipeline = lambda x: 0 if int(x)==-2 else (1 if int(x)==-1 else (2 if int(x)==0 else (3 if int(x)==1 else 4 )))\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text),dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence( text_list, batch_first=True)\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sxEaWbDdd6aN",
   "metadata": {
    "id": "sxEaWbDdd6aN"
   },
   "source": [
    "#### El modelo\n",
    "\n",
    "Se construyo una red neuronal recurrente con:\n",
    "\n",
    "- 2 capas LSTM bidireccionales\n",
    "- 1 capa lineal \n",
    "- 1 capa de dropout con probabilidad 0.4\n",
    "- 1 capa lineal de salida (con dimensión 5 para cada clase)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4-djYydOqo_s",
   "metadata": {
    "id": "4-djYydOqo_s"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_dim, \n",
    "                                      padding_idx=0) \n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size,num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size*2, fc_hidden_size)\n",
    "        self.dropout=nn.Dropout(p=0.4)\n",
    "        self.out_l = nn.Linear(fc_hidden_size, 5)\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        _, (hidden, cell) = self.rnn(out)\n",
    "        out = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.out_l(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PtptT5Owei2T",
   "metadata": {
    "id": "PtptT5Owei2T"
   },
   "source": [
    "Definimos las funciones para entrenar el modelo y evaluarlo con el conjunto de validación. Tomamos las funciones de los notebooks del curso, haciendo pequeñas modificaciones para adaptarlas a nuestro ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nFgryBCD7c9s",
   "metadata": {
    "id": "nFgryBCD7c9s"
   },
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)\n",
    "        loss = loss_fn(pred, label_batch.long())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += (pred.argmax(axis=1).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
    " \n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)\n",
    "            loss = loss_fn(pred, label_batch.long())\n",
    "            total_acc += (pred.argmax(axis=1).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k31SRm3Fe2Fh",
   "metadata": {
    "id": "k31SRm3Fe2Fh"
   },
   "source": [
    "Inicializamos el modelo usando una dimesión de embedding de 100, 100 neuronas en las capas ocultas de LSTM y 60 neuronas en la capa intermedia lineal. Usamos el optimizador **AdamW** y un learning rate de 0.001. Además empleamos la entropía cruzada como función de costo para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "YHm6K58r9I_2",
   "metadata": {
    "id": "YHm6K58r9I_2"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 100\n",
    "rnn_hidden_size = 100\n",
    "fc_hidden_size = 60\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZVBgjohWfigK",
   "metadata": {
    "id": "ZVBgjohWfigK"
   },
   "source": [
    "¡Entrenando el modelo! \n",
    "\n",
    "Usamos 10 epocas porque el modelo es pesado y observamos que entrenar durante más epocas no conducía a mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "C-5GKxSf9OJG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-5GKxSf9OJG",
    "outputId": "ce22e21e-849c-4bd0-995d-aefba97a8cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 => loss: 1.6056 val_loss:1.5931 | accuracy: 0.2007 val_accuracy: 0.2750\n",
      "Epoch 1 => loss: 1.5713 val_loss:1.5835 | accuracy: 0.3333 val_accuracy: 0.2667\n",
      "Epoch 2 => loss: 1.5221 val_loss:1.5685 | accuracy: 0.3943 val_accuracy: 0.2750\n",
      "Epoch 3 => loss: 1.4092 val_loss:1.5971 | accuracy: 0.4158 val_accuracy: 0.2750\n",
      "Epoch 4 => loss: 1.2669 val_loss:1.6538 | accuracy: 0.5161 val_accuracy: 0.2667\n",
      "Epoch 5 => loss: 0.9993 val_loss:1.7066 | accuracy: 0.6487 val_accuracy: 0.3333\n",
      "Epoch 6 => loss: 0.7328 val_loss:1.9064 | accuracy: 0.7384 val_accuracy: 0.3250\n",
      "Epoch 7 => loss: 0.4827 val_loss:2.0956 | accuracy: 0.8315 val_accuracy: 0.2500\n",
      "Epoch 8 => loss: 0.3063 val_loss:2.9646 | accuracy: 0.9211 val_accuracy: 0.2583\n",
      "Epoch 9 => loss: 0.1466 val_loss:2.9666 | accuracy: 0.9498 val_accuracy: 0.2667\n"
     ]
    }
   ],
   "source": [
    "#generando los batchs\n",
    "batch_size = 30  \n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "# entrenando...\n",
    "num_epochs = 10\n",
    "torch.manual_seed(1)\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "train_accs=[]\n",
    "valid_accs=[]\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    train_losses.append(loss_train)\n",
    "    train_accs.append(acc_train)\n",
    "    valid_losses.append(loss_valid)\n",
    "    valid_accs.append(acc_valid)\n",
    "    print(f'Epoch {epoch} => loss: {loss_train:.4f} val_loss:{loss_valid:.4f} | accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6nAx8q4kAcnQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "6nAx8q4kAcnQ",
    "outputId": "5e393f24-dc3f-4e20-93ef-08dd53b5e8ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(16,7))\n",
    "ax[0].plot(range(num_epochs), train_losses, 'r', label='train')\n",
    "ax[0].plot(range(num_epochs), valid_losses, 'b', label = 'valid')\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(range(num_epochs), train_accs, 'r', label='train')\n",
    "ax[1].plot(range(num_epochs), valid_accs, 'b', label = 'valid')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twKuwAdJfw0x",
   "metadata": {
    "id": "twKuwAdJfw0x"
   },
   "source": [
    "De las gráficas de loss y accuracy para los dos conjuntos de datos, encontramos una tendencia al *overfitting*. Al variar tanto los parámetros de la arquitectura de la red como el tiempo de entrenamiento, observamos que el comportamiento no mejora, por lo que concluimos que el problema sean probablemente los datos (comentarios) que: \n",
    "\n",
    "- No han sido completamente procesados\n",
    "- No brindan información suficiente para que la red aprenda el patrón para asignar correctamente las clases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bGhRBhquh3ig",
   "metadata": {
    "id": "bGhRBhquh3ig"
   },
   "source": [
    "### Alistando para producción\n",
    "\n",
    "Se definen las funciones `collate_prod` que procesa el texto para ingresarlo al modelo y la función `evalu` que recibe el texto, lo ingresa al modelo y traduce la salida en las etiquetas originales del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "E93IwSYJLp9_",
   "metadata": {
    "id": "E93IwSYJLp9_"
   },
   "outputs": [],
   "source": [
    "def collate_prod(batch):\n",
    "    init_tex=preprocess_sentence(batch)\n",
    "    text_list, lengths = [], []\n",
    "    processed_text = torch.tensor(text_pipeline(init_tex),dtype=torch.int64)\n",
    "    lengths.append(processed_text.size(0))\n",
    "    lengths = torch.tensor(lengths)\n",
    "    return processed_text.to(device), lengths.to(device)\n",
    "\n",
    "def evalu(Comentario):\n",
    "  L=['Muy negativo','Negativo','Neutral','Positivo','Muy positivo']\n",
    "  pro_comment,lengt=collate_prod(Comentario)\n",
    "  rep=pro_comment.view(1,pro_comment.shape[0])\n",
    "  pred = model(rep, lengt)\n",
    "  label=pred.argmax(axis=1).float().item()\n",
    "  return [(L[int(label)],str(int(label)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RAyzwDUiiOQg",
   "metadata": {
    "id": "RAyzwDUiiOQg"
   },
   "source": [
    "#### GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "DIY9UxOPlELj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "DIY9UxOPlELj",
    "outputId": "11011275-3781-49c2-c0e0-013b83519ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
      "Running on public URL: https://18723.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"https://18723.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f437d3bcf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x7f437fa5be50>,\n",
       " 'http://127.0.0.1:7860/',\n",
       " 'https://18723.gradio.app')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interfaz gráfica\n",
    "iface = gr.Interface(\n",
    "    fn = evalu,\n",
    "    inputs= [\"text\"],\n",
    "    outputs=gr.outputs.HighlightedText(color_map={\"0\": \"red\", \"1\": \"orange\",\"2\":\"gray\",\"3\":\"blue\",\"4\":\"green\"},label='Calificación',show_legend=False),\n",
    "    allow_flagging=\"never\",\n",
    "    title = 'Evaluador de comentarios',\n",
    "    description = 'Ingrese un comentario/review y se le indicará la evaluación del comentario',\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fmPxCDO-ibxc",
   "metadata": {
    "id": "fmPxCDO-ibxc"
   },
   "source": [
    "#### Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lOE1KQO687b3",
   "metadata": {
    "id": "lOE1KQO687b3"
   },
   "source": [
    "En este caso, a partir de los pesos directamente no es posible encontrar qué partes de los comentarios aportan más a determinar el label del comentario, porque al hacer el *embedding*, ya no existe una correspondencia entre las palabras y los pesos de la red en sus diferentes capas. Sin embargo, pudimos encontrar algunos patrones relacionados con ciertas palabras en los comentarios y el label asociado. Por ejemplo, la palabra **muy** se relaciona con el label *muy positivo*, dado que siempre que se incluye en un comentario, el modelo le asigna esa clase. Esto se debe, probablemente, a que muchos comentarios del conjunto de entrenamiento que tenian la palabra **muy** estaban clasificados como *muy positivos*. Igualmente, la palabra **no** se asocia con la clase *negativo*, de hecho, algunos comentarios que son positivos si incluyen la palabra **no** serán clasificados como negativos. Por lo que podemos concluir que, en efecto hay palabras que son más importantes al momento de calcular la clase y consideramos que esas palabras importantes se asocian con la frecuencia con la que aparecen al momento de entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9lWrG6AXKmRa",
   "metadata": {
    "id": "9lWrG6AXKmRa"
   },
   "source": [
    "# Parte 2: Problema de clasificación por palabras o frases (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uNJogECmttL8",
   "metadata": {
    "id": "uNJogECmttL8"
   },
   "source": [
    "Luego de realizar el debido etiquetado de cada una de las frases pertenecientes a los comentarios del índice 200 al 250, procedemos a crear el dataframe con dichos comentarios y sus etiquetas por frases. Para ello, creamos dos columnas, `data`, donde se encuentra el texto de cada uno de los comentarios, y `label`, donde se encuentran listas con los labels correspondientes a las frases de ese comentario, y las posiciones exactas de estos labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "AzIe0nQSKlkE",
   "metadata": {
    "id": "AzIe0nQSKlkE"
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns = ['text', 'label'])\n",
    "with open('admin.jsonl','r', encoding='cp1252') as f:\n",
    "    str_contents = f.read()\n",
    "    contents_aux = str_contents.split('\\n')\n",
    "    contents = [str(i) for i in contents_aux]\n",
    "    i=0\n",
    "    for line in contents:\n",
    "      try:\n",
    "        data = json.loads(line)\n",
    "        df2.loc[i] = [(data[\"data\"]), list(data[\"label\"])]\n",
    "        i += 1\n",
    "      except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7jgisbYzKzpZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7jgisbYzKzpZ",
    "outputId": "0041f666-a2ad-4f01-8fa3-943d5c34c7f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7f0acb33-24aa-4d84-a3c4-0e3567cae9ef\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>me parece un articulo interesante que pudo cen...</td>\n",
       "      <td>[[0, 33, Positivo], [940, 1053, Neutro]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. el articulo esta muy mal escrito. por ejempl...</td>\n",
       "      <td>[[2, 34, Muy negativo], [245, 293, Negativo], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en mi opinion, siendo la propuesta de muy alto...</td>\n",
       "      <td>[[54, 108, Negativo], [111, 166, Positivo], [3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>el articulo describe los conceptos de data war...</td>\n",
       "      <td>[[239, 263, Negativo], [265, 348, Muy negativo]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>si bien este articulo deja ver una buena canti...</td>\n",
       "      <td>[[8, 60, Positivo], [62, 128, Negativo], [129,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f0acb33-24aa-4d84-a3c4-0e3567cae9ef')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7f0acb33-24aa-4d84-a3c4-0e3567cae9ef button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7f0acb33-24aa-4d84-a3c4-0e3567cae9ef');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  me parece un articulo interesante que pudo cen...   \n",
       "1  . el articulo esta muy mal escrito. por ejempl...   \n",
       "2  en mi opinion, siendo la propuesta de muy alto...   \n",
       "3  el articulo describe los conceptos de data war...   \n",
       "4  si bien este articulo deja ver una buena canti...   \n",
       "\n",
       "                                               label  \n",
       "0           [[0, 33, Positivo], [940, 1053, Neutro]]  \n",
       "1  [[2, 34, Muy negativo], [245, 293, Negativo], ...  \n",
       "2  [[54, 108, Negativo], [111, 166, Positivo], [3...  \n",
       "3   [[239, 263, Negativo], [265, 348, Muy negativo]]  \n",
       "4  [[8, 60, Positivo], [62, 128, Negativo], [129,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dWkrlkRtuv9R",
   "metadata": {
    "id": "dWkrlkRtuv9R"
   },
   "source": [
    "Ahora, creamos una función que, de acuerdo con la lista de labels obtenida de codificar manualmente las frases de cada comentario, nos permite etiquetar cada palabra. En caso de que haya palabras que no estén etiquetadas, pertenecen a la clase `otros`. Además, definimos cada categoría numéricamente, es decir: \n",
    "- Otros = 0\n",
    "- Muy negativo = 1\n",
    "- Negativo = 2\n",
    "- Neutro = 3\n",
    "- Positivo = 4\n",
    "- Muy positivo = 5\n",
    "\n",
    "Definimos, a su vez, una función para quitar la puntuación de los comentarios, para evitar problemas futuros con la codificación de las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "n6XN2Ufua1Tk",
   "metadata": {
    "id": "n6XN2Ufua1Tk"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def quitar(list_text):\n",
    "  new_text = list_text.copy()\n",
    "  dic = ['a', 'o', 'y', 'u', 'e']\n",
    "  for palabra in list_text:\n",
    "    if len(palabra) == 1 and palabra not in dic:\n",
    "      new_text.remove(palabra)\n",
    "  return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "Cbz-l4uvK1KQ",
   "metadata": {
    "id": "Cbz-l4uvK1KQ"
   },
   "outputs": [],
   "source": [
    "def codificar(texto, labels):\n",
    "  dic_labels = {\"Otros\": 0,\n",
    "                \"Muy negativo\": 1,\n",
    "                \"Negativo\": 2,\n",
    "                \"Neutro\": 3,\n",
    "                \"Positivo\":4,\n",
    "                \"Muy postivo\": 5}\n",
    "  palabras = texto.split()\n",
    "  cod = []\n",
    "  idxs0 = []\n",
    "  idxs1 = []\n",
    "  labels_ = []\n",
    "  for label in labels:\n",
    "    idx0, idx1, lab = label\n",
    "    idxs0.append(idx0)\n",
    "    idxs1.append(idx1)\n",
    "    labels_.append(lab)\n",
    "  for i in range(len(idxs0)):\n",
    "    last = 0 \n",
    "    if i == 0 and idxs0[i] != 0:\n",
    "      cant_palabras3 = len(texto[0: idxs0[i]-1].split())\n",
    "      cod += [dic_labels[\"Otros\"]]*cant_palabras3\n",
    "      last = idxs0[i]-1\n",
    "\n",
    "    cant_palabras = len(texto[idxs0[i]: idxs1[i]].split())\n",
    "    cod += [dic_labels[labels_[i]]]*cant_palabras\n",
    "    last = idxs1[i]\n",
    "    if i < len(idxs0)-1:\n",
    "      cant_palabras2 = len(texto[idxs1[i]+1: idxs0[i+1]].split())\n",
    "      cod += [dic_labels[\"Otros\"]]*cant_palabras2\n",
    "      last = idxs0[i+1]\n",
    "\n",
    "    elif i == len(idxs1)-1 and idxs1[i] != len(texto):\n",
    "      cant_palabras4 = len(texto[idxs1[i]+1:].split())\n",
    "      cod += [dic_labels[\"Otros\"]]*cant_palabras4\n",
    "      last = len(texto)\n",
    "\n",
    "  return cod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SV2nH0hRvLyd",
   "metadata": {
    "id": "SV2nH0hRvLyd"
   },
   "source": [
    "Definimos, nuevamente, una clase `TextData2`, que nos permite la división de los datos en datos de entrenamiento y validación. Para ello, una vez más, tomamos el 70% y el 30%, respectivamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "BmpmjIXZK6c9",
   "metadata": {
    "id": "BmpmjIXZK6c9"
   },
   "outputs": [],
   "source": [
    "class TextData2(Dataset):\n",
    "    '''\n",
    "    Dataset basico para leer los datos de tweets\n",
    "    '''\n",
    "    def __init__(self, dataFrame):\n",
    "        super(TextData2, self).__init__()\n",
    "        #df = pd.read_csv(filename,encoding='latin-1')\n",
    "        self.df = dataFrame[[\"label\", \"text\"]]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.df.iloc[index,0], self.df.iloc[index,1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "uYevaK8WT0ig",
   "metadata": {
    "id": "uYevaK8WT0ig"
   },
   "outputs": [],
   "source": [
    "corpus = df2.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "oe9osRcILGJs",
   "metadata": {
    "id": "oe9osRcILGJs"
   },
   "outputs": [],
   "source": [
    "TextD2 = TextData2(df2)\n",
    "train_dataset, valid_dataset = random_split(TextD2, [int(len(TextD2)*0.7), len(TextD2) - int(len(TextD2)*0.7)], torch.manual_seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17YBzubJveGY",
   "metadata": {
    "id": "17YBzubJveGY"
   },
   "source": [
    "Creamos el vocabulario al procesar los datos de entrenamiento, y nuevamente introducimos los tokens correspondientes a palabras desconocidas y de relleno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "mML7Y9aoLNJu",
   "metadata": {
    "id": "mML7Y9aoLNJu"
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "\n",
    "tok_c = Counter()\n",
    "for label, line in train_dataset:\n",
    "    tokens = line.split()\n",
    "    tok_c.update(tokens)\n",
    "\n",
    "\n",
    "sorted_by_freq_tuples = sorted(tok_c.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "vocab = vocab(ordered_dict)\n",
    "\n",
    "vocab.insert_token(\"<pad>\", 0)\n",
    "vocab.insert_token(\"<unk>\", 1)\n",
    "vocab.set_default_index(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qrVHisgfvvmM",
   "metadata": {
    "id": "qrVHisgfvvmM"
   },
   "source": [
    "Nuevamente definimos funciones que usaremos en el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "wSIraH59LQV7",
   "metadata": {
    "id": "wSIraH59LQV7"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "text_pipeline = lambda x: [vocab[token] for token in x.split()]\n",
    "label_pipeline = lambda x, y: [codificar(x,y)]\n",
    "\n",
    "def collate_batch2(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _labels, _text in batch:\n",
    "        processed_label=torch.tensor(codificar(_text, _labels))      \n",
    "        label_list.append(processed_label)\n",
    "        processed_text = torch.tensor(text_pipeline(_text), \n",
    "                                      dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
    "        text_list, batch_first=True)\n",
    "    label_list = nn.utils.rnn.pad_sequence(\n",
    "        label_list, batch_first=True, padding_value=0)\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e_F-i0ctAodX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_F-i0ctAodX",
    "outputId": "e2920954-a559-4ce3-9626-0494cf557918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 319])\n",
      "torch.Size([15, 320])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(train_dataset, batch_size=15, shuffle=True, collate_fn=collate_batch2)\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "print(text_batch.shape)\n",
    "print(label_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-qMdaW3Uv3JI",
   "metadata": {
    "id": "-qMdaW3Uv3JI"
   },
   "source": [
    "### Modelo\n",
    "Ahora, construimos una red neuronal recurrente con las siguientes capas:\n",
    "- 2 capas LSTM bidireccionales\n",
    "- 1 capa lineal \n",
    "- 1 capa de dropout con probabilidad 0.4\n",
    "- 1 capa lineal de salida (con dimensión 6 para cada clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aSaFGpX7LUSW",
   "metadata": {
    "id": "aSaFGpX7LUSW"
   },
   "outputs": [],
   "source": [
    "class RNN_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_dim, \n",
    "                                      padding_idx=0) \n",
    "        self.rnn = nn.LSTM(embed_dim, fc_hidden_size,num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.dropout=nn.Dropout(p=0.4)\n",
    "        self.out_l = nn.Linear(fc_hidden_size*2, 6)\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        salida, _ = self.rnn(out)\n",
    "        output, lengs = nn.utils.rnn.pad_packed_sequence(salida, batch_first=True)\n",
    "        out = self.dropout(output)\n",
    "        out = self.out_l(out)\n",
    "        return out\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7kWWFWDqwJ6b",
   "metadata": {
    "id": "7kWWFWDqwJ6b"
   },
   "source": [
    "A continuación definimos, nuevamente, las funciones para entrenar y evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "NIArfkMJLktm",
   "metadata": {
    "id": "NIArfkMJLktm"
   },
   "outputs": [],
   "source": [
    "def loss_by_batch(predictions,labels):\n",
    "    ll=0\n",
    "    #print(\"pred: \",predictions.shape)\n",
    "    #print(\"lab: \",labels.shape)\n",
    "    for i in range(predictions.shape[0]):\n",
    "        mini = min([predictions.shape[1], labels.shape[1]])\n",
    "        ll+=loss_fn(predictions[i,:mini,:], labels[i,:mini])\n",
    "    return ll/predictions.shape[0]\n",
    "\n",
    "def train2(dataloader):\n",
    "    model2.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    posiciones=0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        #print(text_batch.shape)\n",
    "        #print(label_batch.shape)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model2(text_batch, lengths)\n",
    "        mini = min([pred.shape[1], label_batch.shape[1]])\n",
    "        pred, label_batch = pred[:,:mini,:], label_batch[:,:mini]\n",
    "        posiciones += text_batch.shape[0]*text_batch.shape[1]\n",
    "        loss = loss_by_batch(pred, label_batch.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += (pred.argmax(axis=2).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/posiciones, total_loss/posiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orKgQLD_wS5M",
   "metadata": {
    "id": "orKgQLD_wS5M"
   },
   "source": [
    "Nuestro nuevo modelo es inicializado con una dimensión de embedding de 200, con 200 neuronas ocultas, y 64 neuronas en la capa intermedia lineal. Una vez más, hacemos uso del optimizador **AdamW**, y de una tasa de aprendizaje de 0.001. Entrenamos el modelo con la función de costo de entropía cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "jgD_K8CqM740",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgD_K8CqM740",
    "outputId": "34cf0f9e-7d40-4db6-9bf9-e45f4253f29a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of RNN_NER(\n",
      "  (embedding): Embedding(1596, 200, padding_idx=0)\n",
      "  (rnn): LSTM(200, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (out_l): Linear(in_features=128, out_features=6, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "#Cambiar parametros\n",
    "embed_dim = 200\n",
    "rnn_hidden_size = 200\n",
    "fc_hidden_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model2 = RNN_NER(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model2 = model2.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model2.parameters(), lr=0.001)\n",
    "\n",
    "print(model2.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q6fDWfozw9AG",
   "metadata": {
    "id": "q6fDWfozw9AG"
   },
   "source": [
    "### Entrenamiento del modelo\n",
    "\n",
    "Definimos una función para evaluar el modelo, y para entrenar el nuevo modelo, usamos 15 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "gS1Yj8buhodI",
   "metadata": {
    "id": "gS1Yj8buhodI"
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model2.eval()\n",
    "    total_acc, total_loss, count = 0, 0, 0\n",
    "    posiciones = 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model2(text_batch, lengths)\n",
    "            mini = min([pred.shape[1], label_batch.shape[1]])\n",
    "            pred, label_batch = pred[:,:mini,:], label_batch[:,:mini]\n",
    "            P=pred.argmax(axis=2).float()\n",
    "            loss = loss_by_batch(pred,label_batch.long())\n",
    "            total_acc += (pred.argmax(axis=2).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "            count += lengths.sum()\n",
    "            posiciones += text_batch.shape[0]*text_batch.shape[1]\n",
    "    return total_acc/posiciones, total_loss/posiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69bc96",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con los datos seleccionados para este propósito, y observamos el accuracy y el loss en cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "AhnX_k-FNH_W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhnX_k-FNH_W",
    "outputId": "5bc6724e-71a5-49e1-bf34-3d19858f721b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 => loss: 0.0066 | accuracy: 0.3172 | val_loss: 0.007970066511467712 | val_accuracy: 0.44315068493150683\n",
      "Epoch 1 => loss: 0.0060 | accuracy: 0.4593 | val_loss: 0.006895026536745446 | val_accuracy: 0.4837383177570094\n",
      "Epoch 2 => loss: 0.0052 | accuracy: 0.7504 | val_loss: 0.006259172448614762 | val_accuracy: 0.8714060031595576\n",
      "Epoch 3 => loss: 0.0047 | accuracy: 0.8776 | val_loss: 0.006072472433719967 | val_accuracy: 0.8714060031595576\n",
      "Epoch 4 => loss: 0.0049 | accuracy: 0.8647 | val_loss: 0.00621348398703116 | val_accuracy: 0.8689210950080515\n",
      "Epoch 5 => loss: 0.0048 | accuracy: 0.8712 | val_loss: 0.006597868049384471 | val_accuracy: 0.8511882998171847\n",
      "Epoch 6 => loss: 0.0046 | accuracy: 0.8683 | val_loss: 0.006225825172581085 | val_accuracy: 0.8606164383561644\n",
      "Epoch 7 => loss: 0.0047 | accuracy: 0.8633 | val_loss: 0.006600410018586154 | val_accuracy: 0.8508226691042048\n",
      "Epoch 8 => loss: 0.0044 | accuracy: 0.8665 | val_loss: 0.006783697243364463 | val_accuracy: 0.8493601462522852\n",
      "Epoch 9 => loss: 0.0042 | accuracy: 0.8869 | val_loss: 0.007222816974632919 | val_accuracy: 0.8446069469835467\n",
      "Epoch 10 => loss: 0.0040 | accuracy: 0.9082 | val_loss: 0.006674987682397815 | val_accuracy: 0.8486312399355878\n",
      "Epoch 11 => loss: 0.0038 | accuracy: 0.9204 | val_loss: 0.007970532384724047 | val_accuracy: 0.8212523719165086\n",
      "Epoch 12 => loss: 0.0036 | accuracy: 0.9372 | val_loss: 0.0072220851833693644 | val_accuracy: 0.8521739130434782\n",
      "Epoch 13 => loss: 0.0035 | accuracy: 0.9396 | val_loss: 0.007295567695408651 | val_accuracy: 0.8256849315068493\n",
      "Epoch 14 => loss: 0.0034 | accuracy: 0.9426 | val_loss: 0.007092293781503493 | val_accuracy: 0.8499210110584519\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "training = DataLoader(train_dataset,  batch_size=int(batch_size), shuffle=True, collate_fn=collate_batch2)\n",
    "valid = DataLoader(valid_dataset,  batch_size=int(batch_size), shuffle=True, collate_fn=collate_batch2)\n",
    "\n",
    "#Entrenando el modelo\n",
    "num_epochs = 15\n",
    "torch.manual_seed(1)\n",
    "train_losses=[]\n",
    "train_accs=[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  acc_train, loss_train = train2(training)\n",
    "  train_losses.append(loss_train)\n",
    "  train_accs.append(acc_train)\n",
    "  acc_val, val_loss = evaluate(valid)\n",
    "  print(f'Epoch {epoch} => loss: {loss_train:.4f} | accuracy: {acc_train:.4f} | val_loss: {val_loss} | val_accuracy: {acc_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "SlZnlrhXjLLh",
   "metadata": {
    "id": "SlZnlrhXjLLh"
   },
   "outputs": [],
   "source": [
    "class RNN_NER2(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_dim, \n",
    "                                      padding_idx=0) \n",
    "        self.rnn = nn.LSTM(embed_dim, fc_hidden_size,num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.dropout=nn.Dropout(p=0.4)\n",
    "        self.out_l = nn.Linear(fc_hidden_size*2, 6)\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        salida, _ = self.rnn(out)\n",
    "        output, lengs = nn.utils.rnn.pad_packed_sequence(salida, batch_first=True)\n",
    "        out = self.dropout(output)\n",
    "        out = self.out_l(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "GrlHUVZ3n0Dj",
   "metadata": {
    "id": "GrlHUVZ3n0Dj"
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model3.eval()\n",
    "    total_acc, total_loss, count = 0, 0, 0\n",
    "    posiciones = 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model2(text_batch, lengths)\n",
    "            mini = min([pred.shape[1], label_batch.shape[1]])\n",
    "            pred, label_batch = pred[:,:mini,:], label_batch[:,:mini]\n",
    "            P=pred.argmax(axis=2).float()\n",
    "            loss = loss_by_batch(pred,label_batch.long())\n",
    "            total_acc += (pred.argmax(axis=2).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "            count += lengths.sum()\n",
    "            posiciones += text_batch.shape[0]*text_batch.shape[1]\n",
    "    return total_acc/posiciones, total_loss/posiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "wRStgwuLoNMm",
   "metadata": {
    "id": "wRStgwuLoNMm"
   },
   "outputs": [],
   "source": [
    "def train3(dataloader):\n",
    "    model3.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    posiciones=0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        #print(text_batch.shape)\n",
    "        #print(label_batch.shape)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model3(text_batch, lengths)\n",
    "        mini = min([pred.shape[1], label_batch.shape[1]])\n",
    "        pred, label_batch = pred[:,:mini,:], label_batch[:,:mini]\n",
    "        posiciones += text_batch.shape[0]*text_batch.shape[1]\n",
    "        loss = loss_by_batch(pred, label_batch.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += (pred.argmax(axis=2).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/posiciones, total_loss/posiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb0c5d",
   "metadata": {},
   "source": [
    "Ahora probamos el modelo con los datos de validación, observando nuevamente el valor del accuracy y del loss en cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ps9tPsoqngoA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ps9tPsoqngoA",
    "outputId": "1aa454dd-694a-499b-addb-ff0177f3d71f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of RNN_NER2(\n",
      "  (embedding): Embedding(1596, 200, padding_idx=0)\n",
      "  (rnn): LSTM(200, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (out_l): Linear(in_features=128, out_features=6, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "#Cambiar parametros\n",
    "embed_dim = 200\n",
    "rnn_hidden_size = 200\n",
    "fc_hidden_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model3 = RNN_NER2(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "#model3.embedding.weight = model.embedding.weight\n",
    "model3 = model3.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model3.parameters(), lr=0.001)\n",
    "\n",
    "print(model3.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "UUq1JmJgoC9S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUq1JmJgoC9S",
    "outputId": "dc912ab5-a6b5-4d9d-8c89-516faec556d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 => loss: 0.0066 | accuracy: 0.3172 | val_loss: 0.0075695426904991885 | val_accuracy: 0.8373287671232876\n",
      "Epoch 1 => loss: 0.0060 | accuracy: 0.4593 | val_loss: 0.008233742624799782 | val_accuracy: 0.822429906542056\n",
      "Epoch 2 => loss: 0.0052 | accuracy: 0.7504 | val_loss: 0.007119984611704075 | val_accuracy: 0.8499210110584519\n",
      "Epoch 3 => loss: 0.0047 | accuracy: 0.8776 | val_loss: 0.007032055048769308 | val_accuracy: 0.8499210110584519\n",
      "Epoch 4 => loss: 0.0049 | accuracy: 0.8647 | val_loss: 0.007311162549324466 | val_accuracy: 0.8470209339774557\n",
      "Epoch 5 => loss: 0.0048 | accuracy: 0.8712 | val_loss: 0.008024376968579057 | val_accuracy: 0.8263254113345521\n",
      "Epoch 6 => loss: 0.0046 | accuracy: 0.8683 | val_loss: 0.00767328437060526 | val_accuracy: 0.8373287671232876\n",
      "Epoch 7 => loss: 0.0047 | accuracy: 0.8633 | val_loss: 0.008059420794847897 | val_accuracy: 0.8263254113345521\n",
      "Epoch 8 => loss: 0.0044 | accuracy: 0.8665 | val_loss: 0.008174204957114713 | val_accuracy: 0.8263254113345521\n",
      "Epoch 9 => loss: 0.0042 | accuracy: 0.8869 | val_loss: 0.007905874871248737 | val_accuracy: 0.8263254113345521\n",
      "Epoch 10 => loss: 0.0040 | accuracy: 0.9082 | val_loss: 0.007289945983272436 | val_accuracy: 0.8470209339774557\n",
      "Epoch 11 => loss: 0.0038 | accuracy: 0.9204 | val_loss: 0.008765758554216128 | val_accuracy: 0.8197343453510436\n",
      "Epoch 12 => loss: 0.0036 | accuracy: 0.9372 | val_loss: 0.007293171736737188 | val_accuracy: 0.8470209339774557\n",
      "Epoch 13 => loss: 0.0035 | accuracy: 0.9396 | val_loss: 0.007668015279182016 | val_accuracy: 0.8373287671232876\n",
      "Epoch 14 => loss: 0.0034 | accuracy: 0.9426 | val_loss: 0.007092293781503493 | val_accuracy: 0.8499210110584519\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "training = DataLoader(train_dataset,  batch_size=int(batch_size), shuffle=True, collate_fn=collate_batch2)\n",
    "valid = DataLoader(valid_dataset,  batch_size=int(batch_size), shuffle=True, collate_fn=collate_batch2)\n",
    "\n",
    "#Entrenando el modelo\n",
    "num_epochs = 15\n",
    "torch.manual_seed(1)\n",
    "train_losses=[]\n",
    "train_accs=[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  acc_train, loss_train = train3(training)\n",
    "  train_losses.append(loss_train)\n",
    "  train_accs.append(acc_train)\n",
    "  acc_val, val_loss = evaluate(valid)\n",
    "  print(f'Epoch {epoch} => loss: {loss_train:.4f} | accuracy: {acc_train:.4f} | val_loss: {val_loss} | val_accuracy: {acc_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a522a9",
   "metadata": {},
   "source": [
    "### Análisis\n",
    "\n",
    "Se observa que, tanto al entrenar el modelo como al probarlo, se obtienen valores de accuracy muy altos, ya que en ambos casos se llega a un accuracy de cerca del 80%. Es posible observar, además, que es mejor iniciar el modelo con los pesos obtenidos en la parte uno. Esto se evidencia en el accuracy obtenido en las primeras épocas, ya que desde el inicio se logra un buen valor de accuracy, mientras que al entrenar el modelo con pesos aleatorios se logra un buen accuracy después de varias épocas. Esto nos permite pensar que, al entrenar el modelo con los pesos obtenidos anteriormente, como se inicia obteniendo valores altos de accuracy desde la primera época, en este tipo de red sería posible entrenar con menos épocas, y hacer un modelo más simple, ya que hacer un modelo más complejo podría llevarnos a un overfitting. Además, se evidencia que tanto al iniciar el modelo con pesos aleatorios como con los pesos de la parte uno, se obtiene un valor de loss muy bajo en cada una de las épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0180a9c",
   "metadata": {},
   "source": [
    "## Conclusiones \n",
    "\n",
    "- Se observa que clasificar primero por frases, y después por palabras, es mucho mejor en términos de accuracy y loss que clasificar con un solo label por comentario, que fue lo realizado en la parte uno. Esto se debe a que, al clasificar de la forma en que se hizo en la parte dos, se permite que la red comprenda mejor el patrón de los datos, ya que la información es mucho más específica para acda palabra. \n",
    "\n",
    "- Los pesos de uan tarea sí ayudan a la otra. Esto se evidencia al momento de entrenar el modelo de la parte dos con los pesos obtenidos en la parte uno, ya que, a pesar de que el accuracy al final de las épocas es muy similar al obtenido con los pesos aleatorios, este accuracy empieza siendo alto desde la primera época, mientras que en el otro caso no.\n",
    "\n",
    "- No es posible determinar, a partir de los pesos, qué parte del texto aporta más al momento de determinar el label del comentario, en la parte uno. Esto se debe a que, para hacer el *embedding*, no hay una correspondencia entre las palabras y los pesos en las diferentes capas de la red.Sin embargo, debido a los patrones identificados con ciertas palabras, se evidencia que hay algunas palabras que son más importantes al momento de calcular la clase, y esta importancia se asocia a la frecuencia con la que aparecen estas palabras en el texto, al entrenar el modelo."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Proyecto2_comentado.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
